{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7+mvfTbYcTZD7fKnc8aXb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muntasir-islam/Beginner-Friendly-WordPress-Design-Learning-Path/blob/main/Spam_Email_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload and Import data"
      ],
      "metadata": {
        "id": "8srnxowHcguh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DzUbQy-H2_lr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c75436b-9c38-4d4c-8c7e-32d07e1a4a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  spam\n",
            "0  Subject: naturally irresistible your corporate...     1\n",
            "1  Subject: the stock trading gunslinger  fanny i...     1\n",
            "2  Subject: unbelievable new homes made easy  im ...     1\n",
            "3  Subject: 4 color printing special  request add...     1\n",
            "4  Subject: do not have money , get software cds ...     1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv('emails.csv')\n",
        "print(dataset.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Email Spam Detector — venky73 Spam Mails Dataset\n",
        "# ==============================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Download NLTK stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# ------------------------------\n",
        "# 1. Load Dataset\n",
        "# ------------------------------\n",
        "df = pd.read_csv(\"emails.csv\")  # make sure filename matches\n",
        "\n",
        "print(\"Columns in dataset:\", df.columns)\n",
        "print(df.head())\n",
        "\n",
        "# ------------------------------\n",
        "# 2. Rename columns to standard format\n",
        "# ------------------------------\n",
        "# This dataset has: 'text' (email content) and 'spam' (0/1)\n",
        "df = df[['text', 'spam']].copy()\n",
        "df.columns = ['text', 'label']   # rename for consistency\n",
        "print(\"Renamed columns:\", df.columns)\n",
        "\n",
        "# ------------------------------\n",
        "# 3. Preprocess Text\n",
        "# ------------------------------\n",
        "ps = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text)\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)   # keep only letters\n",
        "    words = text.lower().split()\n",
        "    words = [ps.stem(w) for w in words if w not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "df['cleaned_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "# ------------------------------\n",
        "# 4. Features & Labels\n",
        "# ------------------------------\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(df['cleaned_text']).toarray()\n",
        "\n",
        "y = df['label'].values  # already 0 (ham) and 1 (spam)\n",
        "\n",
        "# ------------------------------\n",
        "# 5. Train-Test Split\n",
        "# ------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 6. Logistic Regression\n",
        "# ------------------------------\n",
        "print(\"\\n===== Logistic Regression =====\")\n",
        "ml_model = LogisticRegression(max_iter=200)\n",
        "ml_model.fit(X_train, y_train)\n",
        "y_pred_ml = ml_model.predict(X_test)\n",
        "\n",
        "print(\"ML Accuracy:\", accuracy_score(y_test, y_pred_ml))\n",
        "print(\"ML Report:\\n\", classification_report(y_test, y_pred_ml))\n",
        "\n",
        "# ------------------------------\n",
        "# 7. ANN Model\n",
        "# ------------------------------\n",
        "print(\"\\n===== ANN Model =====\")\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "ann_model = Sequential()\n",
        "ann_model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
        "ann_model.add(Dropout(0.3))\n",
        "ann_model.add(Dense(64, activation='relu'))\n",
        "ann_model.add(Dropout(0.3))\n",
        "ann_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "ann_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "ann_model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1, verbose=1)\n",
        "\n",
        "loss, acc = ann_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"ANN Test Accuracy:\", acc)\n",
        "\n",
        "# ------------------------------\n",
        "# 8. Prediction Function\n",
        "# ------------------------------\n",
        "def predict_email(text):\n",
        "    ct = clean_text(text)\n",
        "    vec = vectorizer.transform([ct]).toarray()\n",
        "    ml_pred = ml_model.predict(vec)[0]\n",
        "    ann_pred = ann_model.predict(vec)[0][0]\n",
        "\n",
        "    print(\"\\nEmail:\", text)\n",
        "    print(\"ML Prediction:\", \"Spam\" if ml_pred == 1 else \"Ham\")\n",
        "    print(\"ANN Prediction:\", \"Spam\" if ann_pred > 0.5 else \"Ham\")\n",
        "\n",
        "# Test with custom emails\n",
        "predict_email(\"Congratulations! You've won a free $1000 gift card. Click below!\")\n",
        "predict_email(\"Hey John, are we still meeting for coffee tomorrow?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdePclekcfDo",
        "outputId": "29051a89-bab3-46d7-b7d3-6010b3c61e1e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in dataset: Index(['text', 'spam'], dtype='object')\n",
            "                                                text  spam\n",
            "0  Subject: naturally irresistible your corporate...     1\n",
            "1  Subject: the stock trading gunslinger  fanny i...     1\n",
            "2  Subject: unbelievable new homes made easy  im ...     1\n",
            "3  Subject: 4 color printing special  request add...     1\n",
            "4  Subject: do not have money , get software cds ...     1\n",
            "Renamed columns: Index(['text', 'label'], dtype='object')\n",
            "\n",
            "===== Logistic Regression =====\n",
            "ML Accuracy: 0.9781849912739965\n",
            "ML Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       856\n",
            "           1       0.99      0.93      0.96       290\n",
            "\n",
            "    accuracy                           0.98      1146\n",
            "   macro avg       0.98      0.96      0.97      1146\n",
            "weighted avg       0.98      0.98      0.98      1146\n",
            "\n",
            "\n",
            "===== ANN Model =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7945 - loss: 0.4405 - val_accuracy: 0.9891 - val_loss: 0.0345\n",
            "Epoch 2/5\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9930 - loss: 0.0237 - val_accuracy: 0.9956 - val_loss: 0.0144\n",
            "Epoch 3/5\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9978 - val_loss: 0.0101\n",
            "Epoch 4/5\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 8.8794e-04 - val_accuracy: 0.9956 - val_loss: 0.0098\n",
            "Epoch 5/5\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.4342e-04 - val_accuracy: 0.9956 - val_loss: 0.0107\n",
            "ANN Test Accuracy: 0.9912739992141724\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\n",
            "Email: Congratulations! You've won a free $1000 gift card. Click below!\n",
            "ML Prediction: Spam\n",
            "ANN Prediction: Spam\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\n",
            "Email: Hey John, are we still meeting for coffee tomorrow?\n",
            "ML Prediction: Ham\n",
            "ANN Prediction: Ham\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# EASY Email Spam Detector\n",
        "# ==============================\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# 1. Load dataset\n",
        "df = pd.read_csv(\"emails.csv\")   # dataset has \"text\" and \"spam\" (0/1)\n",
        "df = df[['text', 'spam']]\n",
        "df.columns = ['text', 'label']\n",
        "\n",
        "# 2. Text Cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub('[^a-zA-Z]', ' ', str(text))  # remove numbers/punctuation\n",
        "    words = text.lower().split()\n",
        "    words = [w for w in words if w not in stop_words]  # remove stopwords\n",
        "    return \" \".join(words)\n",
        "\n",
        "df['cleaned_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "# 3. Features (X) and Labels (y)\n",
        "vectorizer = TfidfVectorizer(max_features=2000)\n",
        "X = vectorizer.fit_transform(df['cleaned_text']).toarray()\n",
        "y = df['label'].values\n",
        "\n",
        "# 4. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ==============================\n",
        "# A. Machine Learning Model (Logistic Regression)\n",
        "# ==============================\n",
        "ml_model = LogisticRegression(max_iter=200)\n",
        "ml_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nML Accuracy:\", accuracy_score(y_test, ml_model.predict(X_test)))\n",
        "\n",
        "# ==============================\n",
        "# B. ANN Model (Neural Network)\n",
        "# ==============================\n",
        "ann_model = Sequential([\n",
        "    Dense(64, activation='relu', input_dim=X_train.shape[1]),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "ann_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n",
        "\n",
        "loss, acc = ann_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"ANN Accuracy:\", acc)\n",
        "\n",
        "# ==============================\n",
        "# C. Prediction Function\n",
        "# ==============================\n",
        "def predict_email(text):\n",
        "    cleaned = clean_text(text)\n",
        "    vec = vectorizer.transform([cleaned]).toarray()\n",
        "    ml_pred = ml_model.predict(vec)[0]\n",
        "    ann_pred = ann_model.predict(vec)[0][0]\n",
        "\n",
        "    print(\"\\nEmail:\", text)\n",
        "    print(\"ML →\", \"Spam\" if ml_pred == 1 else \"Ham\")\n",
        "    print(\"ANN →\", \"Spam\" if ann_pred > 0.5 else \"Ham\")\n",
        "\n",
        "# Try it\n",
        "predict_email(\"Congratulations! You won a FREE iPhone. Click now!\")\n",
        "predict_email(\"Hey, I have an urgent meeting with you tommorow at sharp 8 pm\")\n",
        "predict_email(\"Everyone's talking about this except you\")\n",
        "predict_email(\"Event Reminder – Line Following Robot Workshop & Competition\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJSgSWhjfJFD",
        "outputId": "9d9c645f-0179-4c3e-b03d-3542a15dae76"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ML Accuracy: 0.9755671902268761\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8142 - loss: 0.4400\n",
            "Epoch 2/5\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0376\n",
            "Epoch 3/5\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0076\n",
            "Epoch 4/5\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0035\n",
            "Epoch 5/5\n",
            "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0021\n",
            "ANN Accuracy: 0.988656222820282\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\n",
            "Email: Congratulations! You won a FREE iPhone. Click now!\n",
            "ML → Spam\n",
            "ANN → Spam\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\n",
            "Email: Hey, I have an urgent meeting with you tommorow at sharp 8 pm\n",
            "ML → Ham\n",
            "ANN → Ham\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\n",
            "Email: Everyone's talking about this except you\n",
            "ML → Ham\n",
            "ANN → Ham\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\n",
            "Email: Event Reminder – Line Following Robot Workshop & Competition\n",
            "ML → Ham\n",
            "ANN → Ham\n"
          ]
        }
      ]
    }
  ]
}